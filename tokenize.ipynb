{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(txt), dtype = torch.long)\n",
    "n = len(data)*.9\n",
    "train = data[:n]\n",
    "validate = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4 # How many are we processing in parallel at the same time?\n",
    "context_length = 8 #block size, maximum context length for predictions\n",
    "\n",
    "def get_batch(type_of_data):\n",
    "    if type_of_data == \"train\":\n",
    "        data = train\n",
    "    else:\n",
    "        data = validate\n",
    "    #get batch size starting points within the context\n",
    "    ix = torch.randint(len(data)-context_length, (batch_size, ))\n",
    "    x = torch.stack([data[i:i+context_length] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+1+context_length] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "# decoder steps, see things before, things after masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        #each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
